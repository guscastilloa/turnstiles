{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "project_root = (os.path.dirname(os.path.abspath('.')))\n",
    "\n",
    "# Add the project root to sys.path if it's not already there\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "    \n",
    "import src.data.anonymizer as anonymizer\n",
    "from src.data.id_mapper import IDMapper\n",
    "from src.data.file_encoding import detect_file_encoding, batch_detect_encodings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le paramètre `salt` dans la fonction `create_anonymous_id` joue un rôle crucial dans la génération d'ID anonymes de manière sécurisée et déterministe. Voici une explication détaillée de son rôle :\n",
    "\n",
    "1. **Sécurité accrue** : Le `salt` est une valeur aléatoire ajoutée à l'identifiant (`identifier`) avant de générer le hachage. Cela empêche les attaques par dictionnaire et les attaques par force brute, car même si deux identifiants sont identiques, leurs hachages seront différents si des `salt` différents sont utilisés.\n",
    "\n",
    "2. **Déterminisme** : Si un `salt` spécifique est fourni, la fonction générera toujours le même ID anonyme pour un identifiant donné. Cela est utile pour garantir que les mêmes identifiants d'origine produisent les mêmes ID anonymes à chaque exécution, tant que le même `salt` est utilisé.\n",
    "\n",
    "3. **Génération aléatoire** : Si aucun `salt` n'est fourni, la fonction en génère un aléatoirement en utilisant `os.urandom(32)`. Cela garantit que chaque appel à la fonction avec le même identifiant produira un ID anonyme différent, ce qui peut être utile pour des besoins de sécurité spécifiques où le déterminisme n'est pas nécessaire.\n",
    "\n",
    "Example d'usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    hashed = anonymizer.create_anonymous_id(identifier='123123', salt=None)\n",
    "    print(hashed)\n",
    "\n",
    "# Whereas if we include a salt value, the hashed value will be different but consistent\n",
    "print(\"\\nWith salt:\")\n",
    "for i in range(3):\n",
    "    hashed = anonymizer.create_anonymous_id(identifier='123123', salt='000')\n",
    "    print(hashed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IDMapper class\n",
    "It's easy to just create an unique identifer, and it will always return the same value once the salt is supplied (which it is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = IDMapper()\n",
    "[mapper.create_anonymous_id(original_id=\"123123\") for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build sample datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw = os.path.join(project_root, 'data/raw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MjÁlvarez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print full paths of all files in the raw data directory\n",
    "path = \"\".join([path_raw, '/MjÁlvarez'])\n",
    "files = os.listdir(path)\n",
    "\n",
    "# Read each file with pandas\n",
    "df_list = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(path, file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    df_list.append(df)\n",
    "    print(f\"File: {os.path.basename(file_path)}\")\n",
    "    print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given that the dataframes in df_list are adjacency matrices, suggest way to anonimize the rows and columns of the adjacency matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TrustExperiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revise the encoding of the files TrustExperiment\n",
    "\n",
    "encodings = batch_detect_encodings('../data/raw/TrustExperiment', pattern='*.csv')\n",
    "for filename, encoding in encodings.items():\n",
    "    print(f\"{filename}: {encoding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\".join([path_raw, '/TrustExperiment'])\n",
    "files = os.listdir(path)\n",
    "\n",
    "\n",
    "# Read files with the encoding in the encodings dictionary\n",
    "df_list = []\n",
    "for file in files:\n",
    "    file_path = os.path.join(path, file)\n",
    "    df = pd.read_csv(file_path, encoding=encodings[file])\n",
    "    df_list.append(df)\n",
    "    print(f\"File: {os.path.basename(file_path)}\")\n",
    "    print(f\"Shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got to revise the current `MasterIDsFile.csv` and anonymize all the CSV for all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_list[0].anonymousID.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Produce sample data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
