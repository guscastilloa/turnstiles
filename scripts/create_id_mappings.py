# scripts/create_id_mappings.py
# %%
from pathlib import Path
import sys
import os
import pandas as pd
import glob
import logging
from typing import List, Dict

# ====================================================================#
# Walk up the directory tree until you find the project root (contains '.git')
current = os.path.abspath(os.path.dirname(__file__))
while '.git' not in os.listdir(current):
    parent = os.path.dirname(current)
    if parent == current:  # Reached root of filesystem
        break
    current = parent

ROOT_DIR = current
# Add the detected project root to sys.path
sys.path.append(ROOT_DIR)
# ====================================================================#

# Define paths
ROOT_DIR = Path(ROOT_DIR)
INPUT_PATH = ROOT_DIR / "data"
OUTPUT_PATH = ROOT_DIR / "data/id_mappings"
SALT_PATH = ROOT_DIR / "config/secure/salt.key"


from src.data.id_mapper import IDMapper
# %%
logger = logging.getLogger('IDMapper')
logger.setLevel(logging.INFO)

# StreamHandler for console
console_handler = logging.StreamHandler()
logger.addHandler(console_handler)

# FileHandler for file
file_handler = logging.FileHandler(ROOT_DIR / 'logs/id_mappings.log')
logger.addHandler(file_handler)

# Formatter
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
console_handler.setFormatter(formatter)
file_handler.setFormatter(formatter)

# %%
def process_turnstile_data(mapper: IDMapper, input_dir: Path):
    """
    Processes turnstile data files by anonymizing identifiers and writing 
    the first processed file (which will serve as testing stub) to 
    the output directory.

    Args:
        mapper (IDMapper): An object responsible for mapping and anonymizing identifiers.
        input_dir (Path): The directory containing the input CSV files to process.
        output_dir (Path): The directory where the anonymized output file (1 file) will be saved.
    Raises:
        pd.errors.ParserError: If the CSV file cannot be parsed with the default delimiter.
        Exception: For any other errors encountered during processing.
    Notes:
        - This function processes all files in the input directory matching the pattern "P2000*.csv".
        - Only the first processed file is written to the output directory.
        - Logs are generated by IDMapper to indicate the progress and any errors encountered.
    """
    # This code processes turnstile data files, anonymizes identifiers, and writes the first anonymized file to the output directory.
    first_file_written = False
    
    for csv_file in glob.glob(str(input_dir / "P2000*.csv")):
        file_path = Path(csv_file)
        logger.info(f"Processing turnstile file: {file_path.name}")
        
        # Read data
        try:
            df = pd.read_csv(file_path, delimiter=',')
        except pd.errors.ParserError:
            df = pd.read_csv(file_path, delimiter=';')
        
        try:
            df['carnet'] = df['carnet'].astype(str).apply(
                lambda x: mapper.add_identifier(x, source='turnstile')
            )
        except Exception as e:
            logger.error(f"Error processing {file_path.name}: {str(e)}")


def process_survey_data(mapper: IDMapper, input_dir: Path):
    """Treat all MjAlvarez survey data files"""
    first_file_written = False
    
    for csv_file in glob.glob(str(input_dir / "*.csv")):
        file_path = Path(csv_file)
        logger.info(f"Processing survey file: {file_path.name}")
        
        # Read and process the survey data
        try:
            df = pd.read_csv(file_path)
            # The IDs are in the first column and the headers and because
            # these are adjacency matrices, taking the IDs of the first row,
            # , i.e., the colum names, should be enough to get all IDs
                
            student_ids = [str(i) for i in list(df.columns[1:])]
            for student_id in student_ids:
                mapper.add_identifier(str(student_id), source='survey')
        except Exception as e:
            logger.error(f"Error processing {file_path.name}: {str(e)}")

        

def process_trust_data(mapper: IDMapper, input_dir: Path):
    """Treat all TrustExperiment data files"""
    # First: Use MasterIDsFile.csv to replace all files with anonymized IDs
    # produced by the IDMapper and using the carnet as the original ID

    masterfile = pd.read_csv(input_dir)

    # Second: normal processing 
    logger.info(f"Processing trust file: MasterIDsFile.csv")

    for student_id in masterfile['studentID'].unique():
        mapper.add_identifier(str(student_id), source='trust')


# %%
def main():
    """Main function to execute the ID mapping process."""
     
    # Create the IDMapper instance with the salt file
    mapper = IDMapper(SALT_PATH)
    
    # Traiter chaque source de donn√©es
    process_turnstile_data(mapper = mapper,
                           input_dir=INPUT_PATH / "intermediate/daily")
    process_survey_data(mapper = mapper, 
                        input_dir= INPUT_PATH / "raw/survey")
    process_trust_data(mapper = mapper,
                       input_dir= INPUT_PATH / "raw/trust/MasterIDsFile.csv")
    
    # Sauvegarder tous les mappings
    mapper.save_mappings(OUTPUT_PATH)
    logger.info("Completed ID mapping creation for all sources")

if __name__ == "__main__":
    main()    